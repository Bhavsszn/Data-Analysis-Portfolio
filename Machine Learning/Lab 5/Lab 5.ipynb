{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bf09b6-e611-4471-89e5-248e1d98cccb",
   "metadata": {},
   "source": [
    "# CYBR 486 - Lab #5: Perceptron\n",
    "\n",
    "## Overview\n",
    "This lab focuses on using a perceptron model to classify breast cancer data into two categories: malignant or benign. The lab will guide you through tasks such as loading the dataset, splitting it into training and testing sets, training the perceptron model, and evaluating its performance using various metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Load and preprocess the breast cancer dataset.\n",
    "2. Split the dataset into training (80%) and testing (20%) subsets.\n",
    "3. Build and train a perceptron binary classifier using the training set.\n",
    "4. Make predictions and evaluate the model using:\n",
    "    - Confusion Matrix\n",
    "    - Accuracy Score\n",
    "    - Precision Score\n",
    "    - Recall Score\n",
    "5. Visualize the results using a confusion matrix heatmap.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "1. Python 3.x installed on your machine.\n",
    "2. Required Python libraries:\n",
    "   - `scikit-learn`\n",
    "   - `pandas`\n",
    "   - `numpy`\n",
    "   - `seaborn`\n",
    "   - `matplotlib`\n",
    "   \n",
    "To install the required libraries, run the following command:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn pandas numpy seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712a74c-17f0-4486-86a7-324147fb503a",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f81854e-ec26-48ff-9e45-3e6a8d5ff4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0aa2ec-c38f-4556-95ae-7c4f864f5e36",
   "metadata": {},
   "source": [
    "## Step 2: Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715cba02-64a1-4456-98c6-15d1c2a4d610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n",
      "None\n",
      "\n",
      "Null Values Check:\n",
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the breast cancer dataset\n",
    "data_X, data_y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(data_X.info())  # Display data types and non-null values\n",
    "\n",
    "# Check for any null values in the dataset\n",
    "print(\"\\nNull Values Check:\")\n",
    "print(data_X.isnull().sum())  # Check for nulls in the feature data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482081b9-fd32-47f5-8594-052724855b1c",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "1. data_X: Contains the feature variables (e.g., mean radius, texture, area).\n",
    "2. data_y: Contains the target variable (malignant or benign).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949c4e5-75b1-4c2f-9271-a2cce2e4030b",
   "metadata": {},
   "source": [
    "## Step 3: Split the Dataset into Training and Testing Subsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11bcbd9-2f47-4564-98ff-c09224509743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (455, 30)\n",
      "Testing Set Shape: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting splits\n",
    "print(\"Training Set Shape:\", X_train.shape)\n",
    "print(\"Testing Set Shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c3251-1cf4-48ec-84b6-187c733016b4",
   "metadata": {},
   "source": [
    "## Step 4: Build and Train the Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de47d9d9-542f-4dc4-9c28-98a8c050ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perceptron Model Trained.\n"
     ]
    }
   ],
   "source": [
    "# Create a Perceptron model\n",
    "perceptron_model = Perceptron(random_state=42)\n",
    "\n",
    "# Train the model using the training set\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "\n",
    "# Display a message confirming the model has been trained\n",
    "print(\"\\nPerceptron Model Trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f372a9-b7a8-494c-83fc-f99150dbb292",
   "metadata": {},
   "source": [
    "## Step 5: Make Predictions and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45d893d-159d-4306-989a-5c4c85931fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[43  0]\n",
      " [15 56]]\n",
      "\n",
      "Accuracy Score: 0.868421052631579\n",
      "Precision Score: 1.0\n",
      "Recall Score: 0.7887323943661971\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = perceptron_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall Score:\", recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd41cc8-9203-4cbf-8737-c2086f220596",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "1. Confusion Matrix: A table used to evaluate the performance of classification models by comparing actual vs predicted values.\n",
    "2. Accuracy Score: The proportion of correct predictions.\n",
    "3. Precision Score: The proportion of true positive predictions among all positive predictions.\n",
    "4. Recall Score: The proportion of true positive predictions among all actual positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23739c-13d3-4186-9863-942248578e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
